{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccee845d-a1d5-4d84-ae66-141a6137d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4c7fc28-d002-42e6-90e1-c0be04e571f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda3/envs/ikemen/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/home/hoang/miniconda3/envs/ikemen/lib/python3.10/site-packages/mmcv/cnn/bricks/transformer.py:33: UserWarning: Fail to import ``MultiScaleDeformableAttention`` from ``mmcv.ops.multi_scale_deform_attn``, You should install ``mmcv-full`` if you need this module. \n",
      "  warnings.warn('Fail to import ``MultiScaleDeformableAttention`` from '\n",
      "/home/hoang/miniconda3/envs/ikemen/lib/python3.10/site-packages/mmpose/models/registry.py:9: DeprecationWarning: Registries (BACKBONES, NECKS, HEADS, LOSSES, POSENETS) have been moved to mmpose.models.builder. Importing from mmpose.models.registry will be deprecated in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mmcv import Config, DictAction\n",
    "from mmcv.runner import load_checkpoint\n",
    "from models import build_posenet\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from mmpose.core.evaluation.top_down_eval import _get_max_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec5affb3-6bb8-4a64-b926-7888c1682ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPoseModel(nn.Module):\n",
    "    def __init__(self, backbone, keypoint_head):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.keypoint_head = keypoint_head\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature extraction\n",
    "        features = self.backbone(x)\n",
    "        # Keypoint head (dự đoán heatmap)\n",
    "        feature = features[-1]\n",
    "        out = self.keypoint_head(feature)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc946e6-7967-42d9-8da5-0aec583336b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda3/envs/ikemen/lib/python3.10/site-packages/mmpose/models/detectors/top_down.py:61: DeprecationWarning: `loss_pose` for TopDown is deprecated, use `loss_keypoint` for heads instead. See https://github.com/open-mmlab/mmpose/pull/382 for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cfg_file = \"../configs/top_down/lite_hrnet/mpii/litehrnet_30_mpii_256x256.py\"\n",
    "cfg = Config.fromfile(cfg_file)\n",
    "pretrained_model = build_posenet(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38eaef64-ca0b-4c12-a8fc-f8ed3051e0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ../ckpts/litehrnet_30_mpii_256x256.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for keypoint_head.final_layer.weight: copying a param with shape torch.Size([16, 40, 1, 1]) from checkpoint, the shape in current model is torch.Size([30, 40, 1, 1]).\n",
      "size mismatch for keypoint_head.final_layer.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([30]).\n"
     ]
    }
   ],
   "source": [
    "checkpoint = load_checkpoint(pretrained_model, '../ckpts/litehrnet_30_mpii_256x256.pth', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b731cc05-6e3c-428f-affe-92b965b84c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointCoordHead(nn.Module):\n",
    "    def __init__(self, in_channels, num_keypoints):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),  # (B, C, 1, 1)\n",
    "            nn.Flatten(),             # (B, C)\n",
    "            nn.Linear(in_channels, num_keypoints * 2)  # (B, K*2)\n",
    "        )\n",
    "        self.num_keypoints = num_keypoints\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)  # (B, K*2)\n",
    "        out = out.view(-1, self.num_keypoints, 2)\n",
    "        out = torch.sigmoid(out) # range [0, 1]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55704d10-4add-4e5d-b15b-4714d8ec8e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = pretrained_model.backbone\n",
    "# keypoint_head = pretrained_model.keypoint_head\n",
    "keypoint_head = KeypointCoordHead(40, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d753d613-783c-41cf-9543-4eccb0f1e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomPoseModel(backbone, keypoint_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e9f1bbd-db31-49cb-8c30-b1d905fca513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 256, 256)\n",
    "out = model(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cde054e-a5a7-4eb9-9aeb-e7ce87ad4240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/hoang/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/hoang/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/hoang/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/hoang/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/hoang/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset import FaceKeypointDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94d60666-72c0-4549-851a-7fbdbc7990f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (256, 256) # (w, h)\n",
    "\n",
    "train_dataset = FaceKeypointDataset(data_dir=\"../data_split/train/\", output_size=target_size)\n",
    "test_dataset = FaceKeypointDataset(data_dir=\"../data_split/test/\", output_size=target_size)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=4)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=2)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a32e5d16-8941-4a15-a371-f0021c7fd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap → keypoint coordinates\n",
    "def _get_max_preds_torch(heatmaps: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        heatmaps: Tensor of shape (N, K, H, W)\n",
    "\n",
    "    Returns:\n",
    "        preds: Tensor of shape (N, K, 2) - predicted keypoint coordinates\n",
    "        maxvals: Tensor of shape (N, K, 1) - confidence scores\n",
    "    \"\"\"\n",
    "    assert heatmaps.ndim == 4, \"Heatmaps should be 4D tensor (N, K, H, W)\"\n",
    "\n",
    "    N, K, H, W = heatmaps.shape\n",
    "    heatmaps_reshaped = heatmaps.view(N, K, -1)\n",
    "    maxvals, idx = torch.max(heatmaps_reshaped, dim=2, keepdim=True)\n",
    "\n",
    "    preds = idx.repeat(1, 1, 2).float()\n",
    "    preds[..., 0] = preds[..., 0] % W  # x coord\n",
    "    preds[..., 1] = preds[..., 1] // W  # y coord\n",
    "\n",
    "    # Mask out invalid preds (where confidence == 0)\n",
    "    pred_mask = maxvals > 0\n",
    "    preds *= pred_mask.float()\n",
    "\n",
    "    return preds, maxvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b866b46-f9ff-4f9e-a36c-71d4a5f43c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 30, 2)\n",
      "(16, 30, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmaps = np.random.rand(16, 30, 64, 64)\n",
    "preds, maxvals = _get_max_preds(heatmaps)\n",
    "print(preds.shape)\n",
    "heatmaps_t = torch.from_numpy(heatmaps)\n",
    "preds_t, maxvals_t = _get_max_preds_torch(heatmaps_t)\n",
    "print(preds_t.numpy().shape)\n",
    "np.array_equal(preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aec60da-1a6a-414c-996c-496a68802918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [03:50<00:00, 10.46s/it]\n",
      "Epoch 1 [Val]: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:41<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.026985036124559967 | Val Loss: 0.022187543016943066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [03:09<00:00,  8.60s/it]\n",
      "Epoch 2 [Val]: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:24<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 0.019928581123663622 | Val Loss: 0.01324667383662679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [02:58<00:00,  8.10s/it]\n",
      "Epoch 3 [Val]: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:28<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.011884519491683353 | Val Loss: 0.0069945774633776055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [03:29<00:00,  9.54s/it]\n",
      "Epoch 4 [Val]: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:42<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.005767777646807107 | Val Loss: 0.0032019981352443046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [02:55<00:00,  8.00s/it]\n",
      "Epoch 5 [Val]: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:27<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.0025231385000304067 | Val Loss: 0.0016719363735650074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [02:22<00:00,  6.47s/it]\n",
      "Epoch 6 [Val]: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:36<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.000990283641096374 | Val Loss: 0.0007545578621581874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 [Train]:  23%|█████████████████████████████████████▌                                                                                                                               | 5/22 [00:48<02:44,  9.66s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# print(pred_keypoints, gt_keypoints)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 25\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     28\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/ikemen/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ikemen/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ikemen/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, gt_keypoints, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
    "        # images = images.cuda()\n",
    "        # gt_keypoints = gt_keypoints.cuda()\n",
    "\n",
    "        # Dự đoán heatmaps\n",
    "        pred_heatmaps = model(images)\n",
    "        \n",
    "        # Chuyển heatmaps thành tọa độ keypoints (x, y)\n",
    "        # pred_keypoints, _ = _get_max_preds_torch(pred_heatmaps)\n",
    "        # pred_keypoints = pred_keypoints.requires_grad_(True)\n",
    "        pred_keypoints = pred_heatmaps\n",
    "        # Normalize gt keypoints\n",
    "        gt_keypoints[..., 0] /= target_size[0]  # x / w\n",
    "        gt_keypoints[..., 1] /= target_size[1]  # y / h\n",
    "\n",
    "        # Tính loss giữa các keypoints dự đoán và groundtruth\n",
    "        loss = criterion(pred_keypoints, gt_keypoints)\n",
    "        # print(pred_keypoints, gt_keypoints)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, gt_keypoints, _ in tqdm(test_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
    "            # images = images.cuda()\n",
    "            # gt_keypoints = gt_keypoints.cuda()\n",
    "\n",
    "            # Dự đoán heatmaps\n",
    "            pred_heatmaps = model(images)\n",
    "\n",
    "            # Chuyển heatmaps thành tọa độ keypoints (x, y)\n",
    "            # pred_keypoints, _ = _get_max_preds_torch(pred_heatmaps)\n",
    "            pred_keypoints = pred_heatmaps\n",
    "            gt_keypoints[..., 0] /= target_size[0]\n",
    "            gt_keypoints[..., 1] /= target_size[1]\n",
    "\n",
    "            # Tính loss giữa các keypoints dự đoán và groundtruth\n",
    "            loss = criterion(pred_keypoints, gt_keypoints)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss/len(train_loader)} | Val Loss: {val_loss/len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b481fe-c40c-4a3e-9901-735bd4853537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UDA\n",
    "from utils.dataset import UDAFaceKeypointDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2769eb9-21d8-4cc8-b91c-d5f2b81a2852",
   "metadata": {},
   "outputs": [],
   "source": [
    "uda_dataset = UDAFaceKeypointDataset(data_dir='../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1043503b-359b-4737-8847-2a214a8c6b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda3/envs/ikemen/lib/python3.10/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.8379,  1.8379,  1.8379,  ...,  1.5297,  1.5125,  1.5125],\n",
      "         [ 1.8379,  1.8379,  1.8550,  ...,  1.5125,  1.5125,  1.5297],\n",
      "         [ 1.8550,  1.8379,  1.8379,  ...,  1.4954,  1.4954,  1.5125],\n",
      "         ...,\n",
      "         [-1.2445, -1.2788, -0.8678,  ..., -0.8507, -1.0904, -0.7479],\n",
      "         [-1.1075, -0.8849, -0.8849,  ..., -1.1589, -0.1314, -1.2445],\n",
      "         [-0.7137, -0.6109, -1.1418,  ..., -1.1932, -1.3644, -0.1143]],\n",
      "\n",
      "        [[ 1.6933,  1.6933,  1.6933,  ...,  1.3782,  1.3606,  1.3606],\n",
      "         [ 1.6933,  1.6933,  1.7108,  ...,  1.3606,  1.3606,  1.3782],\n",
      "         [ 1.7108,  1.6933,  1.6933,  ...,  1.3431,  1.3431,  1.3606],\n",
      "         ...,\n",
      "         [-1.1954, -1.2304, -0.8277,  ..., -0.7752, -1.0203, -0.6702],\n",
      "         [-1.0378, -0.8102, -0.8277,  ..., -1.0903, -0.0399, -1.1954],\n",
      "         [-0.6352, -0.5301, -1.0728,  ..., -1.1253, -1.3004, -0.0399]],\n",
      "\n",
      "        [[ 1.2457,  1.2457,  1.2457,  ...,  0.9668,  0.9494,  0.9494],\n",
      "         [ 1.2457,  1.2457,  1.2631,  ...,  0.9494,  0.9494,  0.9668],\n",
      "         [ 1.2631,  1.2457,  1.2457,  ...,  0.9319,  0.9319,  0.9494],\n",
      "         ...,\n",
      "         [-0.7761, -0.8284, -0.3578,  ..., -0.3055, -0.5495, -0.2010],\n",
      "         [-0.6193, -0.3927, -0.3753,  ..., -0.6193,  0.4265, -0.7064],\n",
      "         [-0.2010, -0.0790, -0.6193,  ..., -0.6541, -0.8284,  0.4265]]]) tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         ...,\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "         [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "        [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         ...,\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "         [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "        [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         ...,\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "         [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]]) tensor([[ 2.4948e-01,  0.0000e+00, -1.0364e+01],\n",
      "        [ 1.3360e-17,  2.4948e-01, -8.9174e+01]]) tensor([[  1.0130,   0.5419, -71.0331],\n",
      "        [ -0.5419,   1.0130,  67.7029]])\n"
     ]
    }
   ],
   "source": [
    "for item in uda_dataset:\n",
    "    image_base, image_aug, M_base, M_aug, _ = item.values()\n",
    "    print(image_base, image_aug, M_base, M_aug)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59136c4e-b7fa-4982-bd80-56c2545c82a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
