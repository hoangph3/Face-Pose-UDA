{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccee845d-a1d5-4d84-ae66-141a6137d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4c7fc28-d002-42e6-90e1-c0be04e571f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda3/envs/ikemen/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/home/hoang/miniconda3/envs/ikemen/lib/python3.10/site-packages/mmcv/cnn/bricks/transformer.py:33: UserWarning: Fail to import ``MultiScaleDeformableAttention`` from ``mmcv.ops.multi_scale_deform_attn``, You should install ``mmcv-full`` if you need this module. \n",
      "  warnings.warn('Fail to import ``MultiScaleDeformableAttention`` from '\n",
      "/home/hoang/miniconda3/envs/ikemen/lib/python3.10/site-packages/mmpose/models/registry.py:9: DeprecationWarning: Registries (BACKBONES, NECKS, HEADS, LOSSES, POSENETS) have been moved to mmpose.models.builder. Importing from mmpose.models.registry will be deprecated in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mmcv import Config, DictAction\n",
    "from mmcv.runner import load_checkpoint\n",
    "from models import build_posenet\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from mmpose.core.evaluation.top_down_eval import _get_max_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec5affb3-6bb8-4a64-b926-7888c1682ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPoseModel(nn.Module):\n",
    "    def __init__(self, backbone, keypoint_head):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.keypoint_head = keypoint_head\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Feature extraction\n",
    "        features = self.backbone(x)\n",
    "        # Keypoint head (dự đoán heatmap)\n",
    "        feature = features[-1]\n",
    "        out = self.keypoint_head(feature)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccc946e6-7967-42d9-8da5-0aec583336b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoang/miniconda3/envs/ikemen/lib/python3.10/site-packages/mmpose/models/detectors/top_down.py:61: DeprecationWarning: `loss_pose` for TopDown is deprecated, use `loss_keypoint` for heads instead. See https://github.com/open-mmlab/mmpose/pull/382 for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cfg_file = \"../configs/top_down/lite_hrnet/mpii/litehrnet_30_mpii_256x256.py\"\n",
    "cfg = Config.fromfile(cfg_file)\n",
    "pretrained_model = build_posenet(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38eaef64-ca0b-4c12-a8fc-f8ed3051e0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ../ckpts/litehrnet_30_mpii_256x256.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for keypoint_head.final_layer.weight: copying a param with shape torch.Size([16, 40, 1, 1]) from checkpoint, the shape in current model is torch.Size([30, 40, 1, 1]).\n",
      "size mismatch for keypoint_head.final_layer.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([30]).\n"
     ]
    }
   ],
   "source": [
    "checkpoint = load_checkpoint(pretrained_model, '../ckpts/litehrnet_30_mpii_256x256.pth', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b731cc05-6e3c-428f-affe-92b965b84c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointCoordHead(nn.Module):\n",
    "    def __init__(self, in_channels, num_keypoints):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),  # (B, C, 1, 1)\n",
    "            nn.Flatten(),             # (B, C)\n",
    "            nn.Linear(in_channels, num_keypoints * 2)  # (B, K*2)\n",
    "        )\n",
    "        self.num_keypoints = num_keypoints\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)  # (B, K*2)\n",
    "        out = out.view(-1, self.num_keypoints, 2)\n",
    "        out = torch.sigmoid(out) # range [0, 1]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55704d10-4add-4e5d-b15b-4714d8ec8e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = pretrained_model.backbone\n",
    "# keypoint_head = pretrained_model.keypoint_head\n",
    "keypoint_head = KeypointCoordHead(40, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d753d613-783c-41cf-9543-4eccb0f1e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomPoseModel(backbone, keypoint_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e9f1bbd-db31-49cb-8c30-b1d905fca513",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 30, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 256, 256)\n",
    "out = model(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cde054e-a5a7-4eb9-9aeb-e7ce87ad4240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/hoang/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/hoang/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/hoang/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/hoang/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/hoang/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset import FaceKeypointDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94d60666-72c0-4549-851a-7fbdbc7990f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (256, 256) # (w, h)\n",
    "\n",
    "train_dataset = FaceKeypointDataset(data_dir=\"../data_split/train/\", output_size=target_size)\n",
    "test_dataset = FaceKeypointDataset(data_dir=\"../data_split/test/\", output_size=target_size)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=4)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=2)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a32e5d16-8941-4a15-a371-f0021c7fd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap → keypoint coordinates\n",
    "def _get_max_preds_torch(heatmaps: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        heatmaps: Tensor of shape (N, K, H, W)\n",
    "\n",
    "    Returns:\n",
    "        preds: Tensor of shape (N, K, 2) - predicted keypoint coordinates\n",
    "        maxvals: Tensor of shape (N, K, 1) - confidence scores\n",
    "    \"\"\"\n",
    "    assert heatmaps.ndim == 4, \"Heatmaps should be 4D tensor (N, K, H, W)\"\n",
    "\n",
    "    N, K, H, W = heatmaps.shape\n",
    "    heatmaps_reshaped = heatmaps.view(N, K, -1)\n",
    "    maxvals, idx = torch.max(heatmaps_reshaped, dim=2, keepdim=True)\n",
    "\n",
    "    preds = idx.repeat(1, 1, 2).float()\n",
    "    preds[..., 0] = preds[..., 0] % W  # x coord\n",
    "    preds[..., 1] = preds[..., 1] // W  # y coord\n",
    "\n",
    "    # Mask out invalid preds (where confidence == 0)\n",
    "    pred_mask = maxvals > 0\n",
    "    preds *= pred_mask.float()\n",
    "\n",
    "    return preds, maxvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b866b46-f9ff-4f9e-a36c-71d4a5f43c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 30, 2)\n",
      "(16, 30, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heatmaps = np.random.rand(16, 30, 64, 64)\n",
    "preds, maxvals = _get_max_preds(heatmaps)\n",
    "print(preds.shape)\n",
    "heatmaps_t = torch.from_numpy(heatmaps)\n",
    "preds_t, maxvals_t = _get_max_preds_torch(heatmaps_t)\n",
    "print(preds_t.numpy().shape)\n",
    "np.array_equal(preds, preds_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aec60da-1a6a-414c-996c-496a68802918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [03:50<00:00, 10.46s/it]\n",
      "Epoch 1 [Val]: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:41<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.026985036124559967 | Val Loss: 0.022187543016943066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [03:09<00:00,  8.60s/it]\n",
      "Epoch 2 [Val]: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:24<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 0.019928581123663622 | Val Loss: 0.01324667383662679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [02:58<00:00,  8.10s/it]\n",
      "Epoch 3 [Val]: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:28<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.011884519491683353 | Val Loss: 0.0069945774633776055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [03:29<00:00,  9.54s/it]\n",
      "Epoch 4 [Val]: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:42<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.005767777646807107 | Val Loss: 0.0032019981352443046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [02:55<00:00,  8.00s/it]\n",
      "Epoch 5 [Val]: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:27<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.0025231385000304067 | Val Loss: 0.0016719363735650074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 [Train]: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 22/22 [02:22<00:00,  6.47s/it]\n",
      "Epoch 6 [Val]: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:36<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.000990283641096374 | Val Loss: 0.0007545578621581874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 [Train]:  23%|█████████████████████████████████████▌                                                                                                                               | 5/22 [00:48<02:44,  9.66s/it]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, gt_keypoints, _ in tqdm(train_loader, desc=f\"Epoch {epoch+1} [Train]\"):\n",
    "        # images = images.cuda()\n",
    "        # gt_keypoints = gt_keypoints.cuda()\n",
    "\n",
    "        # Dự đoán heatmaps\n",
    "        pred_heatmaps = model(images)\n",
    "        \n",
    "        # Chuyển heatmaps thành tọa độ keypoints (x, y)\n",
    "        # pred_keypoints, _ = _get_max_preds_torch(pred_heatmaps)\n",
    "        # pred_keypoints = pred_keypoints.requires_grad_(True)\n",
    "        pred_keypoints = pred_heatmaps\n",
    "        # Normalize gt keypoints\n",
    "        gt_keypoints[..., 0] /= target_size[0]  # x / w\n",
    "        gt_keypoints[..., 1] /= target_size[1]  # y / h\n",
    "\n",
    "        # Tính loss giữa các keypoints dự đoán và groundtruth\n",
    "        loss = criterion(pred_keypoints, gt_keypoints)\n",
    "        # print(pred_keypoints, gt_keypoints)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, gt_keypoints, _ in tqdm(test_loader, desc=f\"Epoch {epoch+1} [Val]\"):\n",
    "            # images = images.cuda()\n",
    "            # gt_keypoints = gt_keypoints.cuda()\n",
    "\n",
    "            # Dự đoán heatmaps\n",
    "            pred_heatmaps = model(images)\n",
    "\n",
    "            # Chuyển heatmaps thành tọa độ keypoints (x, y)\n",
    "            # pred_keypoints, _ = _get_max_preds_torch(pred_heatmaps)\n",
    "            pred_keypoints = pred_heatmaps\n",
    "            gt_keypoints[..., 0] /= target_size[0]\n",
    "            gt_keypoints[..., 1] /= target_size[1]\n",
    "\n",
    "            # Tính loss giữa các keypoints dự đoán và groundtruth\n",
    "            loss = criterion(pred_keypoints, gt_keypoints)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {train_loss/len(train_loader)} | Val Loss: {val_loss/len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b481fe-c40c-4a3e-9901-735bd4853537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
